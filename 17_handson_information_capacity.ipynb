{"cells":[{"cell_type":"markdown","metadata":{"id":"FLojvJkdO7DV"},"source":["# Information capacity of Deep learning manifolds\n","\n","* **Authors**:\n","\n","  * author: steevelaquitaine@epfl.ch; laquitainesteeve@gmail.com\n","  * adapted from notebooks by SueYeon Chung, and Cory Stephenson\n","  * duration: 40 minutes\n","\n","\n","* **Learning outcomes**:\n","\n","  * Know how to train a deep learning model for object recognition\n","  * Know how to measure its layers' neural manifold geometry (`dimensionality`, `radius`, `correlation`)\n","  * Know how to measure its `information capacity`.\n","\n","* **System requirements**:\n","\n","  * GPU: RunTime - change runtime type - Hardware accelerator: T4 GPU\n","  * RAM: 12.67GB\n","\n","* **Constrains**\n","\n","  * GPU is available for a short period\n","\n","* **Readings**\n","\n","  * Stephenson, C., Feather, J., Padhy, S., Elibol, O., Tang, H., McDermott, J., & Chung, S. (2019). Untangling in invariant speech recognition. Advances in neural information processing systems, 32.\n","  * https://github.com/steevelaquitaine/neural_manifolds_replicaMFT_Cajal/blob/master/examples/MFTMA_VGG16_example.ipynb\n","\n","**Python prerequisites**:\n","\n","  * installing and importing `libraries`\n","  * using `functions`\n","  * plotting with `matplotlib` library\n","  * machine learning with `scikit-learn` and `pytorch` libraries"]},{"cell_type":"markdown","source":["## (34s) Setup"],"metadata":{"id":"wDvCn83Sf8zq"}},{"cell_type":"code","source":["!python --version # should output Python 3.10.13"],"metadata":{"id":"11fRYijbf_Jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uZq42_zXRa-H"},"outputs":[],"source":["# download information geometry software\n","!git clone https://github.com/steevelaquitaine/neural_manifolds_replicaMFT_Cajal.git\n","\n","# install conda\n","!pip install -q condacolab\n","import condacolab\n","condacolab.install()\n","!which conda\n","\n","# use conda to install dependencies of the info geometry software\n","!conda env update --name base --file /content/neural_manifolds_replicaMFT_Cajal/env.yml\n","!exit\n","!conda init\n","!conda activate base\n","\n","# move to the downloaded software directory\n","import os\n","os.chdir(\"/content/neural_manifolds_replicaMFT_Cajal/\")\n","\n","# install the software\n","!pip install -q -e .\n","\n","# install time tracking software\n","!pip install -q ipython-autotime # time track colab notebook cells\n","%load_ext autotime"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3363,"status":"ok","timestamp":1711536357635,"user":{"displayName":"steeve laquitaine","userId":"08351460388525958343"},"user_tz":-60},"id":"WIuad_-Yi7Bm","outputId":"d51371f7-9f8c-4b01-a03b-e37b9fb5406f"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 3.09 s (started: 2024-03-27 10:45:54 +00:00)\n"]}],"source":["import numpy as np\n","np.random.seed(0)\n","\n","# plotting software\n","import matplotlib.pyplot as plt\n","\n","# dataset software\n","import torch\n","from torchvision import datasets, transforms, models\n","\n","# information geometry software\n","from mftma.manifold_analysis_correlation import manifold_analysis_corr\n","from mftma.utils.make_manifold_data import make_manifold_data\n","from mftma.utils.activation_extractor import extractor\n","from mftma.utils.analyze_pytorch import analyze"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"f_Lffb72WvkQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711536364248,"user_tz":-60,"elapsed":219,"user":{"displayName":"steeve laquitaine","userId":"08351460388525958343"}},"outputId":"4988dfc4-6df1-4d00-8567-e48e1deaa9d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.58 ms (started: 2024-03-27 10:46:04 +00:00)\n"]}],"source":["# define custom functions\n","def train(model, device, train_loader, optimizer):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        output = torch.nn.functional.log_softmax(output, dim=1)\n","        loss = torch.nn.functional.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","def test(model, device, test_loader, epoch):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            output = torch.nn.functional.log_softmax(output, dim=1)\n","            test_loss += torch.nn.functional.nll_loss(output, target, reduction='sum').item()\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set epoch {}: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        epoch, test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))"]},{"cell_type":"markdown","metadata":{"id":"Bw8vEo-EWdK1"},"source":["## Train a Deep learning model of object recognition\n","* The model is VGG16\n","\n","* The image dataset is CIFAR-100\n","  * 100 image classes\n","  * 50 images per class"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":264,"status":"ok","timestamp":1711536405537,"user":{"displayName":"steeve laquitaine","userId":"08351460388525958343"},"user_tz":-60},"id":"4pFBvNxTD8RH","outputId":"fe74700c-293d-4bd5-d780-b3c39a64340f"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 555 µs (started: 2024-03-27 10:46:45 +00:00)\n"]}],"source":["# setup parameters\n","N_CLASSES = 100 # number of image classes in CIFAR-100\n","N_ITER = 20\n","\n","examples_per_class = 50"]},{"cell_type":"code","execution_count":7,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6133,"status":"ok","timestamp":1711536417037,"user":{"displayName":"steeve laquitaine","userId":"08351460388525958343"},"user_tz":-60},"id":"3W-WPSO4VL8q","outputId":"9283f21b-552b-4d5f-c3ee-f7c0662e3e01"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ../data/cifar-100-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 169001437/169001437 [00:01<00:00, 97701791.98it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/cifar-100-python.tar.gz to ../data\n","Files already downloaded and verified\n","time: 5.9 s (started: 2024-03-27 10:46:50 +00:00)\n"]}],"source":["# @title (21s) Create train, test datasets\n","\n","mean = (0.5070751592371323, 0.48654887331495095, 0.4409178433670343)\n","std = (0.2673342858792401, 0.2564384629170883, 0.27615047132568404)\n","\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(15),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)\n","])\n","\n","train_dataset = datasets.CIFAR100('../data', train=True, download=True,\n","                   transform=transform_train)\n","test_dataset = datasets.CIFAR100('../data', train=False, download=True,\n","                   transform=transforms.Compose([\n","                       transforms.ToTensor(),\n","                       transforms.Normalize(mean, std)\n","                   ]))\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1024, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9p1Vv5y5Wapu"},"outputs":[],"source":["# @title (24m) Train and test the model\n","print(\"Using GPU: \", torch.cuda.is_available())\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = models.vgg16(num_classes=N_CLASSES)\n","model = model.to(device)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for i in range(N_ITER):#range(20):\n","    train(model, device, train_loader, optimizer)\n","    test(model, device, test_loader, i)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":189,"status":"ok","timestamp":1711537887786,"user":{"displayName":"steeve laquitaine","userId":"08351460388525958343"},"user_tz":-60},"id":"kuRB9mhBXXaC","outputId":"f27ac4e0-1d71-47a7-b0c3-8f44cfc93d2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.75 ms (started: 2024-03-27 11:11:27 +00:00)\n"]}],"source":["model = model.eval()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"W70ZPMU6XWdL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711537944313,"user_tz":-60,"elapsed":4876,"user":{"displayName":"steeve laquitaine","userId":"08351460388525958343"}},"outputId":"67a317c9-89fb-4842-f41d-1dfd08ae9336"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 4.55 s (started: 2024-03-27 11:12:19 +00:00)\n"]}],"source":["# @title (4s) Create the manifold dataset\n","# To create this, we have to specify the number of classes we want to sample,\n","# which in this case will just be the total number of samples in the dataset,\n","# so N_CLASSES=100. We also need to decide how many examples per class we\n","# want to use, and in this case we will use examples_per_class=50. Note that\n","# using large numbers of examples will result in a much longer runtime. We will\n","# also create the manifold data from the train dataset, and show the test\n","# dataset later.\n","data = make_manifold_data(train_dataset, N_CLASSES, examples_per_class, seed=0)\n","data = [d.to(device) for d in data]"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Lfaizh5-XSx_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711537950968,"user_tz":-60,"elapsed":6675,"user":{"displayName":"steeve laquitaine","userId":"08351460388525958343"}},"outputId":"35fda279-4ea4-4d20-fb77-37a7479f301b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['layer_0_Input',\n"," 'layer_1_Conv2d',\n"," 'layer_3_Conv2d',\n"," 'layer_6_Conv2d',\n"," 'layer_8_Conv2d',\n"," 'layer_11_Conv2d',\n"," 'layer_13_Conv2d',\n"," 'layer_15_Conv2d',\n"," 'layer_18_Conv2d',\n"," 'layer_20_Conv2d',\n"," 'layer_22_Conv2d',\n"," 'layer_25_Conv2d',\n"," 'layer_27_Conv2d',\n"," 'layer_29_Conv2d',\n"," 'layer_33_Linear',\n"," 'layer_36_Linear',\n"," 'layer_39_Linear']"]},"metadata":{},"execution_count":13},{"output_type":"stream","name":"stdout","text":["time: 6.81 s (started: 2024-03-27 11:12:23 +00:00)\n"]}],"source":["# @title (7s) Extract activations from the model\n","# Now we need to extract the activations at each layer of the model when the\n","# manifold data is given as an input. We can use the extractor given in\n","# mftma.utils.activation_extractor, which usually works, though depending on\n","# how the specific model is implemented, might miss some layers. If you do use\n","# it, make sure that all the layers you want to analyze are found! For this\n","# example, we will only look at the Conv2D and Linear layers of VGG16.\n","activations = extractor(model, data, layer_types=['Conv2d', 'Linear'])\n","list(activations.keys())"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"thOALSbg7Vd5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711537957397,"user_tz":-60,"elapsed":226,"user":{"displayName":"steeve laquitaine","userId":"08351460388525958343"}},"outputId":"a3d44b65-afcd-4463-d5e1-7472c6ca1dd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["(50, 3, 32, 32)\n","time: 1.39 ms (started: 2024-03-27 11:12:37 +00:00)\n"]}],"source":["# @title (7s) Describe first layer's activations\n","# a matrix of 50 examples per class x (unit receptive field size)\n","data = activations['layer_0_Input']\n","print(data[0].shape)\n","\n","# X is a list of 100 arrays, one for each class\n","# each array is 50 instances x 3072 features (flattened filter = 3*32*32)\n","X = [d.reshape(d.shape[0], -1).T for d in data]"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"XXVViZpTI6t-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711537967298,"user_tz":-60,"elapsed":225,"user":{"displayName":"steeve laquitaine","userId":"08351460388525958343"}},"outputId":"94d67637-5ee7-4911-e9c4-4ff404382b7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 7.68 ms (started: 2024-03-27 11:12:47 +00:00)\n"]}],"source":["# type(activations)\n","# remove some layers to fit in RAM memory\n","del activations['layer_1_Conv2d']\n","del activations['layer_3_Conv2d']\n","del activations['layer_6_Conv2d']\n","del activations['layer_8_Conv2d']\n","del activations['layer_11_Conv2d']\n","del activations['layer_13_Conv2d']\n","del activations['layer_15_Conv2d']\n","del activations['layer_18_Conv2d']\n","del activations['layer_20_Conv2d']\n","del activations['layer_22_Conv2d']\n","del activations['layer_25_Conv2d']\n","del activations['layer_27_Conv2d']\n","del activations['layer_29_Conv2d']\n","del activations['layer_33_Linear']\n","del activations['layer_36_Linear']\n","del activations['layer_39_Linear']"]},{"cell_type":"code","source":["# number of image classes in layer 0\n","print(len(activations['layer_0_Input']), \"image classes\")\n","\n","# description of layer 0 activations for the first image class\n","n_activation_features = activations['layer_0_Input'][0].shape[0]\n","n_image_per_class = activations['layer_0_Input'][0].shape[1]\n","print(n_activation_features,\"activation features x\", n_image_per_class, \"image per class\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"og5P4l5kpn1K","executionInfo":{"status":"ok","timestamp":1711538893475,"user_tz":-60,"elapsed":3,"user":{"displayName":"steeve laquitaine","userId":"08351460388525958343"}},"outputId":"d9cf146c-de74-41e4-f1f1-f41962599df8"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["100 image classes\n","3072 activation features x 50 image per class\n","time: 845 µs (started: 2024-03-27 11:28:13 +00:00)\n"]}]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ITRSrcnFW6Ez","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711537972297,"user_tz":-60,"elapsed":179,"user":{"displayName":"steeve laquitaine","userId":"08351460388525958343"}},"outputId":"853ec89b-c782-4bfe-96bc-8de9f7998765"},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.05 ms (started: 2024-03-27 11:12:52 +00:00)\n"]}],"source":["# @title (7s) Reduce feature dimensionality\n","\n","# Now we're almost ready to run the analysis on the extracted activations.\n","# The final step is to convert them into the correct shape and pass them to\n","# manifold_analysis_corr. For example, the shape of the activations in\n","# layer_1_Conv2d is (50, 64, 32, 32), which we will flatten to (50, 65536) and\n","# transpose to the (65536, 50) format the analysis expects. This flattening may\n","# not always be appropriate as one might want to analyze each spatial location\n","# (or each timestep of a sequence model) independently.\n","# Additionally, the number of features here is quite a bit larger than needed,\n","# so we'll also do a random projection to 5000 dimensions to save time and\n","# memory usage. This step is optional and shouldn't change the geometry too\n","# much (see the Johnson–Lindenstrauss lemma) but it is useful to save on computation.\n","\n","# takes 1 ms per layer\n","\n","for layer, data, in activations.items():\n","\n","    # X is a list of 100 array, one for each image class\n","    # each array is 50 sample instances x N features\n","    X = [d.reshape(d.shape[0], -1).T for d in data]\n","\n","    # Get the number of features in the flattened data\n","    N = X[0].shape[0]\n","\n","    # If N is greater than 5000, do the random projection to 5000 features\n","    if N > 5000:\n","        print(\"Projecting {}\".format(layer))\n","        M = np.random.randn(5000, N)\n","        M /= np.sqrt(np.sum(M*M, axis=1, keepdims=True))\n","        X = [np.matmul(M, d) for d in X]\n","    activations[layer] = X"]},{"cell_type":"markdown","metadata":{"id":"6qG4CDOOZ6_M"},"source":["## (4m) Measure the manifold geometry"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_tMHkVbNYvD-"},"outputs":[],"source":["# analyze the layer's class activations\n","a, r, d, correlation, K = manifold_analysis_corr(activations['layer_0_Input'], 0, 300, n_reps=1)\n","\n","# compute the geometry metrics\n","capacity = 1/np.mean(1/a)\n","radius = np.mean(r)\n","dimension = np.mean(d)"]},{"cell_type":"code","source":["print(\"capacity: {:4f}, radius {:4f}, dimension {:4f}, correlation {:4f}\".format(capacity, radius, dimension, correlation))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xiaLI0qjtv_9","executionInfo":{"status":"ok","timestamp":1711539685055,"user_tz":-60,"elapsed":239,"user":{"displayName":"steeve laquitaine","userId":"08351460388525958343"}},"outputId":"a91a8395-4c05-4346-e95e-9e8c3a94b1f4"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["capacity: 0.040322, radius 1.558389, dimension 34.696575, correlation 0.326515\n","time: 5.49 ms (started: 2024-03-27 11:41:24 +00:00)\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyPf0hi03xCrhqx8YTzM7YRw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}